{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1mDEIWo6/SURjucFxJ7Dz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghassenov/ML-notebooks/blob/main/Feature_Extraction_of_Text_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction from textual data:\n",
        "* text data cannot be directly used in machine learning models because they require numerical inputs.\n",
        "* Feature Extraction converts text into numerical representations.\n",
        "* two popular methods are Bag of words (bow) and TF-IDF"
      ],
      "metadata": {
        "id": "zCvLkb7EksKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of words (BOW)\n",
        "\n",
        "---\n",
        "\n",
        "* represents text as a bag of words, ignoring grammar and word order.\n",
        "* each document is converted into a vector if word counts\n",
        "* creates vocabulary of all unique words in the dataset.\n",
        "\n",
        "How it works?\n",
        "1. Tokenization : split text into words.\n",
        "2. Vocabulary Creation: collects all unique words.\n",
        "3. vectorization: count occurences of each word in a document."
      ],
      "metadata": {
        "id": "qDKzhV9et7pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of bow"
      ],
      "metadata": {
        "id": "pZjARvh0u2DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
      ],
      "metadata": {
        "id": "dUuiCkuwu0ZS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining sample text data\n",
        "documents = [\n",
        "    \"I love machine learning\",\n",
        "    \"I hate bad movies\",\n",
        "    \"Machine learning is fun\"\n",
        "]"
      ],
      "metadata": {
        "id": "6agYU3HvvT76"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bow implementation\n",
        "# Initialize CountVectorizer\n",
        "bow_vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the documents\n",
        "bow_matrix = bow_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get feature names (vocabulary)\n",
        "print(\"BOW Vocabulary:\", bow_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "import pandas as pd\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=bow_vectorizer.get_feature_names_out())\n",
        "print(\"\\nBag of Words (BOW) Representation:\")\n",
        "print(bow_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3hwO9kWvcdm",
        "outputId": "69646c69-26b0-4077-92a3-17424854810e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOW Vocabulary: ['bad' 'fun' 'hate' 'is' 'learning' 'love' 'machine' 'movies']\n",
            "\n",
            "Bag of Words (BOW) Representation:\n",
            "   bad  fun  hate  is  learning  love  machine  movies\n",
            "0    0    0     0   0         1     1        1       0\n",
            "1    1    0     1   0         0     0        0       1\n",
            "2    0    1     0   1         1     0        1       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "\n",
        "---\n",
        "* Improves BOW by weighing words based on importance.\n",
        "\n",
        "* TF (Term Frequency): How often a word appears in a document.\n",
        "\n",
        "* IDF (Inverse Document Frequency): Penalizes words that appear too frequently across all documents (e.g., \"the\", \"is\").\n",
        "\n",
        "How it works?\n",
        "* TF(t,d)=(Total terms in document d)/(\n",
        "Number of times term t appears in document d)\n",
        "\n",
        "* IDF(t) = log( Total documents/\n",
        "Number of documents containing term t\n",
        " )\n",
        "* TF-IDF(t,d) = TF(t,d) * IDF(t)"
      ],
      "metadata": {
        "id": "UYrW_FJQwRwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF implementaion\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Convert to DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nexWXfAxPu6",
        "outputId": "7cb942e5-7914-432b-df49-c371bf2456d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Representation:\n",
            "       bad       fun     hate        is  learning      love   machine   movies\n",
            "0  0.00000  0.000000  0.00000  0.000000  0.517856  0.680919  0.517856  0.00000\n",
            "1  0.57735  0.000000  0.57735  0.000000  0.000000  0.000000  0.000000  0.57735\n",
            "2  0.00000  0.562829  0.00000  0.562829  0.428046  0.000000  0.428046  0.00000\n"
          ]
        }
      ]
    }
  ]
}